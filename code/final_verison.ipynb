{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from NumpyImageDataset import NumpyImageDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "train_data = np.load('./data/cifar_train_data.npy').transpose((0,2,3,1))\n",
    "train_label = np.load('./data/cifar_train_label.npy')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=42)\n",
    "\n",
    "# Data Scaling & Augmentation\n",
    "trainset = NumpyImageDataset(X_train, y_train, transform=transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(1.0, 1.0), ratio=(1.0, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=12),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.4914,0.4822,0.4465],std=[0.2471,0.2435,0.2616]),\n",
    "    transforms.RandomErasing(p=0.2)\n",
    "]))\n",
    "\n",
    "testset = NumpyImageDataset(X_test, y_test, transform=transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.4914,0.4822,0.4465],std=[0.2471,0.2435,0.2616])\n",
    "]))\n",
    "\n",
    "# Residual Block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "# Neural Network Structure\n",
    "def ConvMixer(dim, kernel_size=5, patch_size=2, n_classes=20):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ),\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes),\n",
    "    )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512,\n",
    "                                         shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model = ConvMixer(dim=256, patch_size=2, kernel_size=5, n_classes=20)\n",
    "model = model.to(device)\n",
    "\n",
    "# Dynamic Learning Rate\n",
    "lr_schedule = lambda t: np.interp([t], [0, 150*2//5, 150*4//5, 150], \n",
    "                                  [0, 0.05, 0.05/20.0, 0])[0]\n",
    "\n",
    "opt = optim.AdamW(model.parameters(), lr=0.05, weight_decay=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Total of 150 Epochs\n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(150):\n",
    "        train_loss, train_acc, n = 0, 0, 0\n",
    "        for i, (X, y) in enumerate(trainloader):\n",
    "            model.train()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
    "            opt.param_groups[0].update(lr=lr)\n",
    "            opt.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(X)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item() * y.size(0)\n",
    "            train_acc += (output.max(1)[1] == y).sum().item()\n",
    "            n += y.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        test_acc, m = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for i, (X, y) in enumerate(testloader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(X)\n",
    "                test_acc += (output.max(1)[1] == y).sum().item()\n",
    "                m += y.size(0)\n",
    "\n",
    "        print(f'Epoch: {epoch} : Train Acc: {train_acc/n:.4f}, Test Acc: {test_acc/m:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "from generate_submission import writeSubmissionFile\n",
    "model.eval()\n",
    "pred_data = np.load('./data/cifar_test_data.npy').transpose((0,2,3,1))\n",
    "tmp_data = np.ones(pred_data.shape[0])\n",
    "\n",
    "# Scale Test Data\n",
    "pred_set = NumpyImageDataset(pred_data, tmp_data, transform=transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.4914,0.4822,0.4465],std=[0.2471,0.2435,0.2616])\n",
    "]))\n",
    "\n",
    "all_pred = []\n",
    "\n",
    "for pred,tmp in pred_set:\n",
    "\n",
    "    pred = pred.unsqueeze(0)  \n",
    "\n",
    "    pred = pred.to(device)\n",
    "    output = model(pred)\n",
    "\n",
    "    output = output.argmax(axis = 1)\n",
    "    output = output.cpu().numpy()\n",
    "    all_pred.append(output)\n",
    "\n",
    "all_pred = np.array(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Submmision\n",
    "writeSubmissionFile(all_pred, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
